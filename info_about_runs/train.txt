Model: "custom_yolo"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_1 (InputLayer)            [(None, 416, 416, 3) 0
__________________________________________________________________________________________________
tf_op_layer_truediv (TensorFlow [(None, 416, 416, 3) 0           input_1[0][0]
__________________________________________________________________________________________________
tf_op_layer_sub (TensorFlowOpLa [(None, 416, 416, 3) 0           tf_op_layer_truediv[0][0]
__________________________________________________________________________________________________
down_stack (Functional)         [(None, 104, 104, 24 1364864     tf_op_layer_sub[0][0]
__________________________________________________________________________________________________
conv2d_transpose (Conv2DTranspo (None, 26, 26, 96)   138336      down_stack[0][3]
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 26, 26, 96)   384         conv2d_transpose[0][0]
__________________________________________________________________________________________________
re_lu (ReLU)                    (None, 26, 26, 96)   0           batch_normalization[0][0]
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 26, 26, 192)  0           re_lu[0][0]
                                                                 down_stack[0][2]
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 52, 52, 32)   55328       concatenate[0][0]
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 32)   128         conv2d_transpose_1[0][0]
__________________________________________________________________________________________________
re_lu_1 (ReLU)                  (None, 52, 52, 32)   0           batch_normalization_1[0][0]
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 64)   0           re_lu_1[0][0]
                                                                 down_stack[0][1]
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 104, 104, 24) 13848       concatenate_1[0][0]
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 104, 104, 24) 96          conv2d_transpose_2[0][0]
__________________________________________________________________________________________________
re_lu_2 (ReLU)                  (None, 104, 104, 24) 0           batch_normalization_2[0][0]
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 104, 104, 48) 0           re_lu_2[0][0]
                                                                 down_stack[0][0]
__________________________________________________________________________________________________
dropout (Dropout)               (None, 104, 104, 48) 0           concatenate_2[0][0]
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 52, 52, 128)  55424       dropout[0][0]
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 128)  512         conv2d[0][0]
__________________________________________________________________________________________________
re_lu_3 (ReLU)                  (None, 52, 52, 128)  0           batch_normalization_3[0][0]
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 26, 26, 64)   73792       re_lu_3[0][0]
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 64)   256         conv2d_1[0][0]
__________________________________________________________________________________________________
re_lu_4 (ReLU)                  (None, 26, 26, 64)   0           batch_normalization_4[0][0]
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 13, 13, 24)   13848       re_lu_4[0][0]
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 24)   96          conv2d_2[0][0]
__________________________________________________________________________________________________
final_output (Reshape)          (None, 13, 13, 3, 8) 0           batch_normalization_5[0][0]
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 1, 1, 1, 112 0
__________________________________________________________________________________________________
hack_layer (Lambda)             (None, 13, 13, 3, 8) 0           final_output[0][0]
                                                                 input_2[0][0]
==================================================================================================
Total params: 1,716,912
Trainable params: 351,312
Non-trainable params: 1,365,600
__________________________________________________________________________________________________

Epoch 1: Learning rate is 0.0004.
Epoch 1/5
2021-12-17 17:43:52.933465: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2021-12-17 17:43:54.108336: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
2021-12-17 17:43:54.190191: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
3868/3868 [==============================] - ETA: 0s - batch: 1933.5000 - size: 7.9987 - loss: 242.9560WARNING:tensorflow:From C:\Users\Dragos\AppData\Local\Programs\Python\Python37-64\lib\site-packages\tensorflow\python\keras\engine\training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.

Epoch 00001: val_loss improved from inf to 188.66144, saving model to weights\model.h5
3868/3868 [==============================] - 625s 162ms/step - batch: 1933.5000 - size: 7.9987 - loss: 242.9560 - val_loss: 188.6614

Epoch 2: Learning rate is 0.00039615801681662597.
Epoch 2/5
3868/3868 [==============================] - ETA: 0s - batch: 1933.5000 - size: 7.9987 - loss: 41.1131
Epoch 00002: val_loss improved from 188.66144 to 48.11669, saving model to weights\model.h5
3868/3868 [==============================] - 621s 161ms/step - batch: 1933.5000 - size: 7.9987 - loss: 41.1131 - val_loss: 48.1167

Epoch 3: Learning rate is 0.0003847797125256318.
Epoch 3/5
3868/3868 [==============================] - ETA: 0s - batch: 1933.5000 - size: 7.9987 - loss: 24.1340
Epoch 00003: val_loss improved from 48.11669 to 35.96982, saving model to weights\model.h5
3868/3868 [==============================] - 634s 164ms/step - batch: 1933.5000 - size: 7.9987 - loss: 24.1340 - val_loss: 35.9698

Epoch 4: Learning rate is 0.00036630234897989396.
Epoch 4/5
3868/3868 [==============================] - ETA: 0s - batch: 1933.5000 - size: 7.9987 - loss: 20.1827
Epoch 00004: val_loss improved from 35.96982 to 34.58440, saving model to weights\model.h5
3868/3868 [==============================] - 622s 161ms/step - batch: 1933.5000 - size: 7.9987 - loss: 20.1827 - val_loss: 34.5844

Epoch 5: Learning rate is 0.0003414360008982502.
Epoch 5/5
3868/3868 [==============================] - ETA: 0s - batch: 1933.5000 - size: 7.9987 - loss: 17.9001
Epoch 00005: val_loss improved from 34.58440 to 24.33951, saving model to weights\model.h5
3868/3868 [==============================] - 628s 162ms/step - batch: 1933.5000 - size: 7.9987 - loss: 17.9001 - val_loss: 24.3395